import os
import json
import argparse
import json5
import re
import sys
import traceback
from pathlib import Path
from typing import Any, Dict
from qwen_agent.agents import Assistant
from qwen_agent.tools.base import BaseTool, register_tool
from qwen_agent.utils.output_beautify import typewriter_print
from pipline_framework import (
    denoise_patch_inference_tool,
    template_match_tool,
    stem2cif_tool,
    property_prediction_tool
)
import warnings
from scipy.optimize import OptimizeWarning
warnings.filterwarnings("ignore", category=OptimizeWarning)


# -----------------------------------------------------------------------
# å…¨å±€é»˜è®¤ï¼ˆå¯è¢« main è¦†ç›–ï¼‰
# -----------------------------------------------------------------------
_PIPELINE_DEFAULTS: Dict[str, str] = {
    "weight_path": "/home/aiprogram/project/yaotian/phase_structure_reconstruction/MOE_model_weights/moe_model.ckpt",
    "label_dir": "/home/aiprogram/project/yaotian/phase_structure_reconstruction/data_generation/label",
    "metadata_csv": "/home/aiprogram/project/yaotian/phase_structure_reconstruction/baseline/property.csv",
}


# ========== å·¥å…·æ³¨å†Œ ==========
@register_tool('denoise_patch_inference_tool')
class DenoisePatchTool(BaseTool):
    description = 'å¯¹STEMå¤§å›¾è¿›è¡Œå»å™ªå’Œpatché‡å»ºï¼Œè¿”å›é‡å»ºå›¾ç‰‡è·¯å¾„'
    parameters = [
        {'name': 'image_path', 'type': 'string', 'description': 'STEMå¤§å›¾è·¯å¾„', 'required': True},
        {'name': 'weight_path', 'type': 'string', 'description': 'å»å™ªæ¨¡å‹æƒé‡è·¯å¾„', 'required': True},
        {'name': 'work_root', 'type': 'string', 'description': 'å·¥ä½œç›®å½•', 'required': True},
        {'name': 'device', 'type': 'string', 'description': 'æ¨ç†è®¾å¤‡', 'required': False, 'default': 'cuda'}
    ]
    def call(self, params: str, **kwargs) -> str:
        args = json5.loads(params)
        result = denoise_patch_inference_tool(**args)
        return json5.dumps(result, ensure_ascii=False)

@register_tool('template_match_tool')
class TemplateMatchTool(BaseTool):
    description = 'å¯¹å»å™ªåå›¾ç‰‡åšæ¨¡æ¿åŒ¹é…ï¼Œè¿”å›æœ€ä½³labelè·¯å¾„å’Œå…ƒç´ ä¿¡æ¯'
    parameters = [
        {'name': 'recon_png', 'type': 'string', 'description': 'å»å™ªåå›¾ç‰‡è·¯å¾„', 'required': True},
        {'name': 'label_dir', 'type': 'string', 'description': 'æ¨¡æ¿åŒ¹é…labelç›®å½•', 'required': True},
        {'name': 'metadata_csv', 'type': 'string', 'description': 'ææ–™å…ƒç´ å…ƒæ•°æ®CSV', 'required': True},
        {'name': 'user_message', 'type': 'string', 'description': 'ç”¨æˆ·è¡¥å……è¯´æ˜', 'required': True},
        {'name': 'work_root', 'type': 'string', 'description': 'å·¥ä½œç›®å½•', 'required': True}
    ]
    def call(self, params: str, **kwargs) -> str:
        args = json5.loads(params)
        result = template_match_tool(**args)
        return json5.dumps(result, ensure_ascii=False)

@register_tool('stem2cif_tool')
class Stem2CifTool(BaseTool):
    description = 'å°†labelå›¾ç‰‡å’Œå…ƒç´ ç±»å‹è½¬æ¢ä¸ºCIFç»“æ„ï¼Œè¿”å›CIFè·¯å¾„'
    parameters = [
        {'name': 'label_path', 'type': 'string', 'description': 'labelå›¾ç‰‡è·¯å¾„', 'required': True},
        {'name': 'elements', 'type': 'array', 'description': 'å…ƒç´ ç±»å‹åˆ—è¡¨', 'required': True},
        {'name': 'work_root', 'type': 'string', 'description': 'å·¥ä½œç›®å½•', 'required': True},
        {'name': 'max_atoms', 'type': 'integer', 'description': 'æœ€å¤§åŸå­æ•°', 'required': False, 'default': 50},
        {'name': 'max_shrink_iter', 'type': 'integer', 'description': 'æœ€å¤§ç¼©å‡è¿­ä»£æ¬¡æ•°', 'required': False, 'default': 4}
    ]
    def call(self, params: str, **kwargs) -> str:
        args = json5.loads(params)
        result = stem2cif_tool(**args)
        return json5.dumps(result, ensure_ascii=False)

@register_tool('property_prediction_tool')
class PropertyPredictionTool(BaseTool):
    description = 'å¯¹CIFç»“æ„è¿›è¡Œç‰©æ€§é¢„æµ‹ï¼Œè¿”å›èƒ½é‡ã€åŠ›ã€åº”åŠ›ç­‰'
    parameters = [
        {'name': 'cif_path', 'type': 'string', 'description': 'CIFç»“æ„è·¯å¾„', 'required': True},
        {'name': 'work_root', 'type': 'string', 'description': 'å·¥ä½œç›®å½•', 'required': True},
        {'name': 'noise_amp', 'type': 'number', 'description': 'æ‰°åŠ¨å¹…åº¦', 'required': False, 'default': 0.05},
        {'name': 'relax_steps', 'type': 'integer', 'description': 'æ¾å¼›æ­¥æ•°', 'required': False, 'default': 500},
        {'name': 'device', 'type': 'string', 'description': 'æ¨ç†è®¾å¤‡', 'required': False, 'default': 'cuda'}
    ]
    def call(self, params: str, **kwargs) -> str:
        args = json5.loads(params)
        result = property_prediction_tool(**args)
        return json5.dumps(result, ensure_ascii=False)

# ========== ä¸»æµç¨‹ ==========
def main():
    parser = argparse.ArgumentParser(description="Qwen2.5-VL å¤šè½®å¯¹è¯Agentï¼ˆQwen-AgentèŒƒå¼ï¼‰")
    parser.add_argument('--model', type=str, default='qwen-plus-2025-04-28')
    parser.add_argument('--model_server', type=str, default='http://localhost:8000/v1')
    parser.add_argument('--api_key', type=str, default=None)
    parser.add_argument('--weight_path', type=str, default=_PIPELINE_DEFAULTS["weight_path"])
    parser.add_argument('--label_dir', type=str, default=_PIPELINE_DEFAULTS["label_dir"])
    parser.add_argument('--metadata_csv', type=str, default=_PIPELINE_DEFAULTS["metadata_csv"])
    parser.add_argument('--work_root', type=str, default='/home/aiprogram/project/yaotian/phase_structure_reconstruction/baseline', help="ä¸€æ¬¡æ€§ pipeline çš„ç»“æœä¿å­˜ç›®å½•")
    args = parser.parse_args()

    llm_cfg = {
        'model': args.model,
        # 'model_server': args.model_server,
        'api_key': args.api_key,
        'generate_cfg': {
            'top_p': 0.8,
            # This parameter will affect the tool-call parsing logic. Default is False:
            # Set to True: when content is `<think>this is the thought</think>this is the answer`
            # Set to False: when response consists of reasoning_content and content
            # 'thought_in_content': True,
            
            # tool-call template: default is nous (recommended for qwen3):
            # 'fncall_prompt_type': 'nous'
            
            # Maximum input length, messages will be truncated if they exceed this length, please adjust according to model API:
            # 'max_input_tokens': 58000
        }
    }

    system_instruction = (
        "ä½ æ˜¯ææ–™ç§‘å­¦æ™ºèƒ½Agentï¼Œèƒ½å¤Ÿå¯¹STEMè¡¨å¾å›¾åƒè¿›è¡Œç»“æ„é‡å»ºä¸ç‰©æ€§åˆ†æã€‚"
        "ä½ å¯ä»¥è°ƒç”¨å¦‚ä¸‹å·¥å…·å®Œæˆå»å™ªã€æ¨¡æ¿åŒ¹é…ã€ç»“æ„é‡å»ºã€ç‰©æ€§é¢„æµ‹ç­‰ä»»åŠ¡ã€‚"
        "æ¯æ¬¡ç”¨æˆ·è¾“å…¥åï¼Œä½ åº”æ ¹æ®éœ€æ±‚åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ï¼Œ"
        "å¹¶åœ¨éœ€è¦æ—¶è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…·å’Œå‚æ•°ã€‚"
        "ä½ å¯ä»¥å¤šè½®å¯¹è¯ï¼Œæ”¯æŒç”¨æˆ·è¡¥å……è¯´æ˜ã€è¿½é—®ã€ç»“æœè§£é‡Šç­‰ã€‚"
        f"å…¨å±€å‚æ•°ï¼šweight_path={args.weight_path}ï¼Œlabel_dir={args.label_dir}ï¼Œmetadata_csv={args.metadata_csv}ï¼Œwork_root={args.work_root}"
    )

    tools = [
        'denoise_patch_inference_tool',
        'template_match_tool',
        'stem2cif_tool',
        'property_prediction_tool'
    ]

    bot = Assistant(
        llm=llm_cfg,
        system_message=system_instruction,
        function_list=tools
    )

    # Step 4: Run the agent as a chatbot.
    messages = []
    print("ğŸ”¹ Qwen2.5-VL Agent å¯åŠ¨ï¼Œè¾“å…¥ exit/quit é€€å‡ºã€‚")
    
    while True:
        # For example, enter the query "draw a dog and rotate it 90 degrees".
        query = input('\nuser query: ')
        # Append the user query to the chat history.
        messages.append({'role': 'user', 'content': query})
        response = []
        response_plain_text = ''
        print('bot response:')
        for response in bot.run(messages=messages):
            # Streaming output.
            response_plain_text = typewriter_print(response, response_plain_text)
        
        # Append the bot responses to the chat history.
        messages.extend(response)


if __name__ == "__main__":
    main()